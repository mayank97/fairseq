Namespace(activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, arch='roberta_base', attention_dropout=0.1, best_checkpoint_metric='accuracy', bpe='gpt2', bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='sentence_ranking', curriculum=0, data='data/CommonsenseQA', dataset_impl=None, ddp_backend='no_c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_ffn_embed_dim=3072, encoder_layers=12, end_learning_rate=0.0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, gpt2_encoder_json='https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', gpt2_vocab_bpe='https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe', init_token=0, keep_interval_updates=-1, keep_last_epochs=-1, log_format='simple', log_interval=25, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=0, max_positions=512, max_sentences=16, max_sentences_valid=16, max_tokens=None, max_tokens_valid=None, max_update=3000, maximize_best_checkpoint_metric=True, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, no_epoch_checkpoints=True, no_last_checkpoints=True, no_progress_bar=False, no_save=False, no_save_optimizer_state=True, num_classes=5, num_workers=1, optimizer='adam', optimizer_overrides='{}', pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, required_batch_size_multiple=8, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='/home/mayank15055/baseline/fairseq/model/roberta.base/model.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, save_predictions=None, seed=1, sentence_avg=False, skip_invalid_size_inputs_valid_test=False, task='commonsense_qa', tbmf_wrapper=False, tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, total_num_update=3000, train_subset='train', update_freq=[1], use_bmuf=False, user_dir='/home/mayank15055/baseline/fairseq/examples/roberta/commonsense_qa', valid_subset='valid', validate_interval=1, warmup_updates=150, weight_decay=0.01)
| dictionary: 50265 types
| Loaded valid with 1221 samples
RobertaModel(
  (decoder): RobertaEncoder(
    (sentence_encoder): TransformerSentenceEncoder(
      (embed_tokens): Embedding(50265, 768, padding_idx=1)
      (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)
      (layers): ModuleList(
        (0): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (6): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (7): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (8): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (9): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (10): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (11): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (emb_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): RobertaLMHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
  )
  (classification_heads): ModuleDict(
    (sentence_classification_head): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (out_proj): Linear(in_features=768, out_features=1, bias=True)
    )
  )
)
| model roberta_base, criterion SentenceRankingCriterion
| num. model params: 125288026 (num. trained: 125288026)
| training on 1 GPUs
| max tokens per GPU = None and max sentences per GPU = 16
Overwriting classification_heads.sentence_classification_head.dense.weight
Overwriting classification_heads.sentence_classification_head.dense.bias
Overwriting classification_heads.sentence_classification_head.out_proj.weight
Overwriting classification_heads.sentence_classification_head.out_proj.bias
| loaded checkpoint /home/mayank15055/baseline/fairseq/model/roberta.base/model.pt (epoch 0 @ 0 updates)
| loading train data for epoch 0
| Loaded train with 9741 samples
| epoch 001:     25 / 609 loss=2.324, nll_loss=0.097, ppl=1.07, wps=936, ups=2, wpb=385.231, bsz=16.000, num_updates=26, lr=1.73333e-06, gnorm=1.386, clip=0.000, oom=0.000, loss_scale=128.000, wall=19, train_wall=11, accuracy=0.165865
| epoch 001:     50 / 609 loss=2.324, nll_loss=0.096, ppl=1.07, wps=931, ups=2, wpb=385.294, bsz=16.000, num_updates=51, lr=3.4e-06, gnorm=1.329, clip=0.000, oom=0.000, loss_scale=128.000, wall=29, train_wall=21, accuracy=0.178922
| epoch 001:     75 / 609 loss=2.323, nll_loss=0.096, ppl=1.07, wps=936, ups=2, wpb=386.132, bsz=16.000, num_updates=76, lr=5.06667e-06, gnorm=1.503, clip=0.000, oom=0.000, loss_scale=128.000, wall=40, train_wall=31, accuracy=0.192434
| epoch 001:    100 / 609 loss=2.322, nll_loss=0.096, ppl=1.07, wps=932, ups=2, wpb=385.446, bsz=16.000, num_updates=101, lr=6.73333e-06, gnorm=1.538, clip=0.000, oom=0.000, loss_scale=128.000, wall=50, train_wall=41, accuracy=0.203589
| epoch 001:    125 / 609 loss=2.322, nll_loss=0.096, ppl=1.07, wps=934, ups=2, wpb=385.048, bsz=16.000, num_updates=126, lr=8.4e-06, gnorm=1.635, clip=0.000, oom=0.000, loss_scale=128.000, wall=60, train_wall=51, accuracy=0.207341
| epoch 001:    150 / 609 loss=2.320, nll_loss=0.096, ppl=1.07, wps=935, ups=2, wpb=384.788, bsz=16.000, num_updates=151, lr=9.99649e-06, gnorm=1.856, clip=0.000, oom=0.000, loss_scale=128.000, wall=70, train_wall=61, accuracy=0.213162
| epoch 001:    175 / 609 loss=2.319, nll_loss=0.096, ppl=1.07, wps=935, ups=2, wpb=385.034, bsz=16.000, num_updates=176, lr=9.90877e-06, gnorm=2.223, clip=0.000, oom=0.000, loss_scale=128.000, wall=81, train_wall=71, accuracy=0.215554
| epoch 001:    200 / 609 loss=2.308, nll_loss=0.096, ppl=1.07, wps=932, ups=2, wpb=384.169, bsz=15.985, num_updates=201, lr=9.82105e-06, gnorm=3.292, clip=0.000, oom=0.000, loss_scale=128.000, wall=91, train_wall=81, accuracy=0.228447
| epoch 001:    225 / 609 loss=2.288, nll_loss=0.095, ppl=1.07, wps=935, ups=2, wpb=384.407, bsz=15.987, num_updates=226, lr=9.73333e-06, gnorm=5.337, clip=0.000, oom=0.000, loss_scale=128.000, wall=101, train_wall=91, accuracy=0.245226
| epoch 001:    250 / 609 loss=2.269, nll_loss=0.094, ppl=1.07, wps=935, ups=2, wpb=383.928, bsz=15.988, num_updates=251, lr=9.64561e-06, gnorm=6.902, clip=0.000, oom=0.000, loss_scale=128.000, wall=111, train_wall=101, accuracy=0.258659
| epoch 001:    275 / 609 loss=2.254, nll_loss=0.094, ppl=1.07, wps=937, ups=2, wpb=384.855, bsz=15.989, num_updates=276, lr=9.55789e-06, gnorm=8.564, clip=0.000, oom=0.000, loss_scale=128.000, wall=122, train_wall=111, accuracy=0.271244
| epoch 001:    300 / 609 loss=2.237, nll_loss=0.093, ppl=1.07, wps=937, ups=2, wpb=384.355, bsz=15.990, num_updates=301, lr=9.47018e-06, gnorm=9.789, clip=0.000, oom=0.000, loss_scale=128.000, wall=132, train_wall=121, accuracy=0.282568
| epoch 001:    325 / 609 loss=2.219, nll_loss=0.092, ppl=1.07, wps=936, ups=2, wpb=384.061, bsz=15.991, num_updates=326, lr=9.38246e-06, gnorm=10.879, clip=0.000, oom=0.000, loss_scale=128.000, wall=142, train_wall=131, accuracy=0.291387
| epoch 001:    350 / 609 loss=2.193, nll_loss=0.091, ppl=1.07, wps=936, ups=2, wpb=384.014, bsz=15.991, num_updates=351, lr=9.29474e-06, gnorm=12.125, clip=0.000, oom=0.000, loss_scale=128.000, wall=152, train_wall=141, accuracy=0.303937
| epoch 001:    375 / 609 loss=2.170, nll_loss=0.090, ppl=1.06, wps=937, ups=2, wpb=384.160, bsz=15.992, num_updates=376, lr=9.20702e-06, gnorm=13.274, clip=0.000, oom=0.000, loss_scale=128.000, wall=162, train_wall=151, accuracy=0.314984
| epoch 001:    400 / 609 loss=2.148, nll_loss=0.089, ppl=1.06, wps=938, ups=2, wpb=384.200, bsz=15.993, num_updates=401, lr=9.1193e-06, gnorm=14.431, clip=0.000, oom=0.000, loss_scale=128.000, wall=172, train_wall=161, accuracy=0.325433
| epoch 001:    425 / 609 loss=2.130, nll_loss=0.089, ppl=1.06, wps=938, ups=2, wpb=384.218, bsz=15.993, num_updates=426, lr=9.03158e-06, gnorm=15.313, clip=0.000, oom=0.000, loss_scale=128.000, wall=183, train_wall=171, accuracy=0.33392
| WARNING: overflow detected, setting loss scale to: 64.0
| epoch 001:    450 / 609 loss=2.117, nll_loss=0.088, ppl=1.06, wps=937, ups=2, wpb=384.282, bsz=15.993, num_updates=450, lr=8.94737e-06, gnorm=16.179, clip=0.000, oom=0.000, loss_scale=64.000, wall=193, train_wall=181, accuracy=0.339864
| epoch 001:    475 / 609 loss=2.099, nll_loss=0.087, ppl=1.06, wps=937, ups=2, wpb=384.560, bsz=15.994, num_updates=475, lr=8.85965e-06, gnorm=16.802, clip=0.000, oom=0.000, loss_scale=64.000, wall=203, train_wall=191, accuracy=0.347769
| epoch 001:    500 / 609 loss=2.084, nll_loss=0.087, ppl=1.06, wps=939, ups=2, wpb=385.008, bsz=15.994, num_updates=500, lr=8.77193e-06, gnorm=17.502, clip=0.000, oom=0.000, loss_scale=64.000, wall=213, train_wall=201, accuracy=0.355008
| epoch 001:    525 / 609 loss=2.068, nll_loss=0.086, ppl=1.06, wps=940, ups=2, wpb=385.309, bsz=15.994, num_updates=525, lr=8.68421e-06, gnorm=18.034, clip=0.000, oom=0.000, loss_scale=64.000, wall=224, train_wall=211, accuracy=0.36251
| epoch 001:    550 / 609 loss=2.057, nll_loss=0.085, ppl=1.06, wps=940, ups=2, wpb=385.289, bsz=15.995, num_updates=550, lr=8.59649e-06, gnorm=18.695, clip=0.000, oom=0.000, loss_scale=64.000, wall=234, train_wall=221, accuracy=0.368762
| epoch 001:    575 / 609 loss=2.043, nll_loss=0.085, ppl=1.06, wps=941, ups=2, wpb=385.397, bsz=15.995, num_updates=575, lr=8.50877e-06, gnorm=19.273, clip=0.000, oom=0.000, loss_scale=64.000, wall=244, train_wall=231, accuracy=0.374796
| epoch 001:    600 / 609 loss=2.030, nll_loss=0.084, ppl=1.06, wps=942, ups=2, wpb=385.852, bsz=15.995, num_updates=600, lr=8.42105e-06, gnorm=19.631, clip=0.000, oom=0.000, loss_scale=64.000, wall=254, train_wall=241, accuracy=0.380015
| epoch 001 | loss 2.026 | nll_loss 0.084 | ppl 1.06 | wps 942 | ups 2 | wpb 385.905 | bsz 15.995 | num_updates 608 | lr 8.39298e-06 | gnorm 19.790 | clip 0.000 | oom 0.000 | loss_scale 64.000 | wall 257 | train_wall 244 | accuracy 0.381491
| epoch 001 | valid on 'valid' subset | loss 1.500 | nll_loss 0.063 | ppl 1.04 | num_updates 608 | accuracy 0.601948
| saved checkpoint checkpoints/checkpoint_best.pt (epoch 1 @ 608 updates) (writing took 0.2878129482269287 seconds)
| epoch 002:     25 / 609 loss=1.550, nll_loss=0.064, ppl=1.05, wps=948, ups=2, wpb=388.423, bsz=16.000, num_updates=634, lr=8.30175e-06, gnorm=30.088, clip=0.000, oom=0.000, loss_scale=64.000, wall=285, train_wall=254, accuracy=0.543269
| epoch 002:     50 / 609 loss=1.572, nll_loss=0.064, ppl=1.05, wps=954, ups=2, wpb=389.941, bsz=16.000, num_updates=659, lr=8.21404e-06, gnorm=33.501, clip=0.000, oom=0.000, loss_scale=64.000, wall=296, train_wall=264, accuracy=0.5625
| epoch 002:     75 / 609 loss=1.584, nll_loss=0.065, ppl=1.05, wps=953, ups=2, wpb=388.803, bsz=16.000, num_updates=684, lr=8.12632e-06, gnorm=35.386, clip=0.000, oom=0.000, loss_scale=64.000, wall=306, train_wall=274, accuracy=0.558388
| epoch 002:    100 / 609 loss=1.588, nll_loss=0.065, ppl=1.05, wps=952, ups=2, wpb=388.228, bsz=16.000, num_updates=709, lr=8.0386e-06, gnorm=35.094, clip=0.000, oom=0.000, loss_scale=64.000, wall=316, train_wall=284, accuracy=0.555693
| epoch 002:    125 / 609 loss=1.590, nll_loss=0.066, ppl=1.05, wps=947, ups=2, wpb=386.746, bsz=16.000, num_updates=734, lr=7.95088e-06, gnorm=34.972, clip=0.000, oom=0.000, loss_scale=64.000, wall=326, train_wall=294, accuracy=0.55506
| epoch 002:    150 / 609 loss=1.590, nll_loss=0.066, ppl=1.05, wps=952, ups=2, wpb=387.291, bsz=16.000, num_updates=759, lr=7.86316e-06, gnorm=34.412, clip=0.000, oom=0.000, loss_scale=64.000, wall=336, train_wall=304, accuracy=0.553394
| epoch 002:    175 / 609 loss=1.598, nll_loss=0.066, ppl=1.05, wps=952, ups=2, wpb=387.801, bsz=16.000, num_updates=784, lr=7.77544e-06, gnorm=34.582, clip=0.000, oom=0.000, loss_scale=64.000, wall=347, train_wall=314, accuracy=0.550071
| epoch 002:    200 / 609 loss=1.588, nll_loss=0.066, ppl=1.05, wps=951, ups=2, wpb=387.567, bsz=16.000, num_updates=809, lr=7.68772e-06, gnorm=34.352, clip=0.000, oom=0.000, loss_scale=64.000, wall=357, train_wall=324, accuracy=0.554726
| epoch 002:    225 / 609 loss=1.595, nll_loss=0.066, ppl=1.05, wps=952, ups=2, wpb=387.345, bsz=15.987, num_updates=834, lr=7.6e-06, gnorm=34.144, clip=0.000, oom=0.000, loss_scale=64.000, wall=367, train_wall=334, accuracy=0.553557
| epoch 002:    250 / 609 loss=1.595, nll_loss=0.066, ppl=1.05, wps=953, ups=2, wpb=387.653, bsz=15.988, num_updates=859, lr=7.51228e-06, gnorm=34.154, clip=0.000, oom=0.000, loss_scale=64.000, wall=377, train_wall=344, accuracy=0.552953
| epoch 002:    275 / 609 loss=1.590, nll_loss=0.066, ppl=1.05, wps=953, ups=2, wpb=387.826, bsz=15.989, num_updates=884, lr=7.42456e-06, gnorm=34.069, clip=0.000, oom=0.000, loss_scale=64.000, wall=387, train_wall=354, accuracy=0.555178
| epoch 002:    300 / 609 loss=1.584, nll_loss=0.065, ppl=1.05, wps=954, ups=2, wpb=387.558, bsz=15.990, num_updates=909, lr=7.33684e-06, gnorm=33.892, clip=0.000, oom=0.000, loss_scale=64.000, wall=397, train_wall=364, accuracy=0.559319
| epoch 002:    325 / 609 loss=1.588, nll_loss=0.065, ppl=1.05, wps=954, ups=2, wpb=387.831, bsz=15.991, num_updates=934, lr=7.24912e-06, gnorm=33.597, clip=0.000, oom=0.000, loss_scale=64.000, wall=407, train_wall=374, accuracy=0.557453
| epoch 002:    350 / 609 loss=1.584, nll_loss=0.065, ppl=1.05, wps=953, ups=2, wpb=387.365, bsz=15.991, num_updates=959, lr=7.1614e-06, gnorm=33.533, clip=0.000, oom=0.000, loss_scale=64.000, wall=417, train_wall=384, accuracy=0.558703
| epoch 002:    375 / 609 loss=1.585, nll_loss=0.066, ppl=1.05, wps=952, ups=2, wpb=386.926, bsz=15.992, num_updates=984, lr=7.07368e-06, gnorm=33.431, clip=0.000, oom=0.000, loss_scale=64.000, wall=428, train_wall=394, accuracy=0.558124
| epoch 002:    400 / 609 loss=1.580, nll_loss=0.065, ppl=1.05, wps=952, ups=2, wpb=387.269, bsz=15.993, num_updates=1009, lr=6.98596e-06, gnorm=33.310, clip=0.000, oom=0.000, loss_scale=64.000, wall=438, train_wall=404, accuracy=0.559333
| epoch 002:    425 / 609 loss=1.579, nll_loss=0.065, ppl=1.05, wps=952, ups=2, wpb=387.127, bsz=15.993, num_updates=1034, lr=6.89825e-06, gnorm=33.281, clip=0.000, oom=0.000, loss_scale=64.000, wall=448, train_wall=414, accuracy=0.558491
| epoch 002:    450 / 609 loss=1.579, nll_loss=0.065, ppl=1.05, wps=951, ups=2, wpb=386.685, bsz=15.993, num_updates=1059, lr=6.81053e-06, gnorm=33.167, clip=0.000, oom=0.000, loss_scale=64.000, wall=458, train_wall=424, accuracy=0.558159
| epoch 002:    475 / 609 loss=1.576, nll_loss=0.065, ppl=1.05, wps=952, ups=2, wpb=386.769, bsz=15.994, num_updates=1084, lr=6.72281e-06, gnorm=33.178, clip=0.000, oom=0.000, loss_scale=64.000, wall=468, train_wall=434, accuracy=0.558124
| epoch 002:    500 / 609 loss=1.573, nll_loss=0.065, ppl=1.05, wps=950, ups=2, wpb=386.244, bsz=15.994, num_updates=1109, lr=6.63509e-06, gnorm=33.140, clip=0.000, oom=0.000, loss_scale=64.000, wall=478, train_wall=444, accuracy=0.558592
| epoch 002:    525 / 609 loss=1.571, nll_loss=0.065, ppl=1.05, wps=951, ups=2, wpb=386.209, bsz=15.994, num_updates=1134, lr=6.54737e-06, gnorm=33.232, clip=0.000, oom=0.000, loss_scale=64.000, wall=488, train_wall=453, accuracy=0.560086
| epoch 002:    550 / 609 loss=1.570, nll_loss=0.065, ppl=1.05, wps=951, ups=2, wpb=386.475, bsz=15.995, num_updates=1159, lr=6.45965e-06, gnorm=33.300, clip=0.000, oom=0.000, loss_scale=64.000, wall=499, train_wall=464, accuracy=0.559401
| epoch 002:    575 / 609 loss=1.566, nll_loss=0.065, ppl=1.05, wps=950, ups=2, wpb=386.311, bsz=15.995, num_updates=1184, lr=6.37193e-06, gnorm=33.262, clip=0.000, oom=0.000, loss_scale=64.000, wall=509, train_wall=474, accuracy=0.560729
| epoch 002:    600 / 609 loss=1.564, nll_loss=0.065, ppl=1.05, wps=950, ups=2, wpb=386.088, bsz=15.995, num_updates=1209, lr=6.28421e-06, gnorm=33.235, clip=0.000, oom=0.000, loss_scale=64.000, wall=519, train_wall=483, accuracy=0.561947
| epoch 002 | loss 1.563 | nll_loss 0.065 | ppl 1.05 | wps 949 | ups 2 | wpb 385.929 | bsz 15.995 | num_updates 1217 | lr 6.25614e-06 | gnorm 33.191 | clip 0.000 | oom 0.000 | loss_scale 64.000 | wall 522 | train_wall 487 | accuracy 0.562468
| epoch 002 | valid on 'valid' subset | loss 1.359 | nll_loss 0.057 | ppl 1.04 | num_updates 1217 | best_accuracy 0.637662 | accuracy 0.637662
| saved checkpoint checkpoints/checkpoint_best.pt (epoch 2 @ 1217 updates) (writing took 0.3621222972869873 seconds)
| epoch 003:     25 / 609 loss=1.311, nll_loss=0.054, ppl=1.04, wps=952, ups=2, wpb=387.731, bsz=16.000, num_updates=1243, lr=6.16491e-06, gnorm=31.967, clip=0.000, oom=0.000, loss_scale=64.000, wall=551, train_wall=497, accuracy=0.625
| epoch 003:     50 / 609 loss=1.363, nll_loss=0.056, ppl=1.04, wps=957, ups=2, wpb=387.549, bsz=16.000, num_updates=1268, lr=6.07719e-06, gnorm=33.528, clip=0.000, oom=0.000, loss_scale=64.000, wall=561, train_wall=507, accuracy=0.612745
| epoch 003:     75 / 609 loss=1.324, nll_loss=0.055, ppl=1.04, wps=949, ups=2, wpb=385.697, bsz=16.000, num_updates=1293, lr=5.98947e-06, gnorm=34.098, clip=0.000, oom=0.000, loss_scale=64.000, wall=572, train_wall=517, accuracy=0.625822
| epoch 003:    100 / 609 loss=1.341, nll_loss=0.055, ppl=1.04, wps=954, ups=2, wpb=387.644, bsz=16.000, num_updates=1318, lr=5.90175e-06, gnorm=34.171, clip=0.000, oom=0.000, loss_scale=64.000, wall=582, train_wall=527, accuracy=0.621287
| epoch 003:    125 / 609 loss=1.326, nll_loss=0.055, ppl=1.04, wps=951, ups=2, wpb=387.468, bsz=16.000, num_updates=1343, lr=5.81404e-06, gnorm=34.365, clip=0.000, oom=0.000, loss_scale=64.000, wall=592, train_wall=537, accuracy=0.623512
| epoch 003:    150 / 609 loss=1.346, nll_loss=0.056, ppl=1.04, wps=949, ups=2, wpb=386.583, bsz=15.980, num_updates=1368, lr=5.72632e-06, gnorm=34.914, clip=0.000, oom=0.000, loss_scale=64.000, wall=602, train_wall=547, accuracy=0.623291
| epoch 003:    175 / 609 loss=1.355, nll_loss=0.056, ppl=1.04, wps=946, ups=2, wpb=384.653, bsz=15.983, num_updates=1393, lr=5.6386e-06, gnorm=34.662, clip=0.000, oom=0.000, loss_scale=64.000, wall=612, train_wall=557, accuracy=0.621756
| epoch 003:    200 / 609 loss=1.356, nll_loss=0.056, ppl=1.04, wps=948, ups=2, wpb=385.458, bsz=15.985, num_updates=1418, lr=5.55088e-06, gnorm=34.714, clip=0.000, oom=0.000, loss_scale=64.000, wall=622, train_wall=567, accuracy=0.625272
| epoch 003:    225 / 609 loss=1.361, nll_loss=0.056, ppl=1.04, wps=946, ups=2, wpb=385.204, bsz=15.987, num_updates=1443, lr=5.46316e-06, gnorm=34.780, clip=0.000, oom=0.000, loss_scale=64.000, wall=633, train_wall=577, accuracy=0.623582
| epoch 003:    250 / 609 loss=1.358, nll_loss=0.056, ppl=1.04, wps=947, ups=2, wpb=385.064, bsz=15.988, num_updates=1468, lr=5.37544e-06, gnorm=34.559, clip=0.000, oom=0.000, loss_scale=64.000, wall=643, train_wall=587, accuracy=0.62447
| epoch 003:    275 / 609 loss=1.362, nll_loss=0.057, ppl=1.04, wps=947, ups=2, wpb=384.899, bsz=15.989, num_updates=1493, lr=5.28772e-06, gnorm=34.725, clip=0.000, oom=0.000, loss_scale=64.000, wall=653, train_wall=597, accuracy=0.624518
| epoch 003:    300 / 609 loss=1.356, nll_loss=0.056, ppl=1.04, wps=947, ups=2, wpb=385.146, bsz=15.990, num_updates=1518, lr=5.2e-06, gnorm=34.559, clip=0.000, oom=0.000, loss_scale=64.000, wall=663, train_wall=607, accuracy=0.627467
| epoch 003:    325 / 609 loss=1.352, nll_loss=0.056, ppl=1.04, wps=945, ups=2, wpb=384.383, bsz=15.991, num_updates=1543, lr=5.11228e-06, gnorm=34.552, clip=0.000, oom=0.000, loss_scale=64.000, wall=673, train_wall=617, accuracy=0.627278
| epoch 003:    350 / 609 loss=1.350, nll_loss=0.056, ppl=1.04, wps=945, ups=2, wpb=384.630, bsz=15.991, num_updates=1568, lr=5.02456e-06, gnorm=34.719, clip=0.000, oom=0.000, loss_scale=64.000, wall=684, train_wall=627, accuracy=0.626581
| epoch 003:    375 / 609 loss=1.350, nll_loss=0.056, ppl=1.04, wps=947, ups=2, wpb=384.971, bsz=15.992, num_updates=1593, lr=4.93684e-06, gnorm=34.824, clip=0.000, oom=0.000, loss_scale=64.000, wall=694, train_wall=637, accuracy=0.625977
| epoch 003:    400 / 609 loss=1.354, nll_loss=0.056, ppl=1.04, wps=947, ups=2, wpb=385.002, bsz=15.993, num_updates=1618, lr=4.84912e-06, gnorm=34.730, clip=0.000, oom=0.000, loss_scale=64.000, wall=704, train_wall=647, accuracy=0.624669
| epoch 003:    425 / 609 loss=1.349, nll_loss=0.056, ppl=1.04, wps=948, ups=2, wpb=385.606, bsz=15.993, num_updates=1643, lr=4.7614e-06, gnorm=34.584, clip=0.000, oom=0.000, loss_scale=64.000, wall=714, train_wall=657, accuracy=0.628064
| epoch 003:    450 / 609 loss=1.352, nll_loss=0.056, ppl=1.04, wps=949, ups=2, wpb=386.120, bsz=15.993, num_updates=1668, lr=4.67368e-06, gnorm=34.674, clip=0.000, oom=0.000, loss_scale=64.000, wall=724, train_wall=667, accuracy=0.626092
| epoch 003:    475 / 609 loss=1.352, nll_loss=0.056, ppl=1.04, wps=949, ups=2, wpb=386.023, bsz=15.994, num_updates=1693, lr=4.58596e-06, gnorm=34.682, clip=0.000, oom=0.000, loss_scale=64.000, wall=734, train_wall=677, accuracy=0.625509
| epoch 003:    500 / 609 loss=1.351, nll_loss=0.056, ppl=1.04, wps=948, ups=2, wpb=386.042, bsz=15.994, num_updates=1718, lr=4.49825e-06, gnorm=34.637, clip=0.000, oom=0.000, loss_scale=64.000, wall=745, train_wall=687, accuracy=0.625983
| epoch 003:    525 / 609 loss=1.347, nll_loss=0.056, ppl=1.04, wps=948, ups=2, wpb=385.654, bsz=15.994, num_updates=1743, lr=4.41053e-06, gnorm=34.766, clip=0.000, oom=0.000, loss_scale=64.000, wall=755, train_wall=696, accuracy=0.627481
| epoch 003:    550 / 609 loss=1.340, nll_loss=0.056, ppl=1.04, wps=948, ups=2, wpb=385.838, bsz=15.995, num_updates=1768, lr=4.32281e-06, gnorm=34.761, clip=0.000, oom=0.000, loss_scale=64.000, wall=765, train_wall=706, accuracy=0.629184
| epoch 003:    575 / 609 loss=1.338, nll_loss=0.055, ppl=1.04, wps=948, ups=2, wpb=385.804, bsz=15.995, num_updates=1793, lr=4.23509e-06, gnorm=34.846, clip=0.000, oom=0.000, loss_scale=64.000, wall=775, train_wall=716, accuracy=0.630631
| epoch 003:    600 / 609 loss=1.334, nll_loss=0.055, ppl=1.04, wps=948, ups=2, wpb=385.824, bsz=15.995, num_updates=1818, lr=4.14737e-06, gnorm=34.826, clip=0.000, oom=0.000, loss_scale=64.000, wall=785, train_wall=726, accuracy=0.632373
| epoch 003 | loss 1.331 | nll_loss 0.055 | ppl 1.04 | wps 948 | ups 2 | wpb 385.929 | bsz 15.995 | num_updates 1826 | lr 4.1193e-06 | gnorm 34.835 | clip 0.000 | oom 0.000 | loss_scale 64.000 | wall 789 | train_wall 730 | accuracy 0.633611
| epoch 003 | valid on 'valid' subset | loss 1.326 | nll_loss 0.055 | ppl 1.04 | num_updates 1826 | best_accuracy 0.645779 | accuracy 0.645779
| saved checkpoint checkpoints/checkpoint_best.pt (epoch 3 @ 1826 updates) (writing took 0.3571281433105469 seconds)
| epoch 004:     25 / 609 loss=1.206, nll_loss=0.051, ppl=1.04, wps=926, ups=2, wpb=380.154, bsz=16.000, num_updates=1852, lr=4.02807e-06, gnorm=38.435, clip=0.000, oom=0.000, loss_scale=64.000, wall=818, train_wall=740, accuracy=0.658654
| epoch 004:     50 / 609 loss=1.150, nll_loss=0.047, ppl=1.03, wps=940, ups=2, wpb=387.882, bsz=16.000, num_updates=1877, lr=3.94035e-06, gnorm=36.775, clip=0.000, oom=0.000, loss_scale=64.000, wall=828, train_wall=750, accuracy=0.680147
| epoch 004:     75 / 609 loss=1.198, nll_loss=0.050, ppl=1.03, wps=931, ups=2, wpb=386.921, bsz=16.000, num_updates=1902, lr=3.85263e-06, gnorm=37.873, clip=0.000, oom=0.000, loss_scale=64.000, wall=839, train_wall=761, accuracy=0.661184
| epoch 004:    100 / 609 loss=1.187, nll_loss=0.049, ppl=1.03, wps=936, ups=2, wpb=386.406, bsz=16.000, num_updates=1927, lr=3.76491e-06, gnorm=36.966, clip=0.000, oom=0.000, loss_scale=64.000, wall=849, train_wall=771, accuracy=0.664604
| epoch 004:    125 / 609 loss=1.193, nll_loss=0.049, ppl=1.03, wps=938, ups=2, wpb=386.008, bsz=16.000, num_updates=1952, lr=3.67719e-06, gnorm=36.684, clip=0.000, oom=0.000, loss_scale=64.000, wall=859, train_wall=781, accuracy=0.662202
| epoch 004:    150 / 609 loss=1.201, nll_loss=0.050, ppl=1.04, wps=941, ups=2, wpb=387.007, bsz=16.000, num_updates=1977, lr=3.58947e-06, gnorm=36.927, clip=0.000, oom=0.000, loss_scale=64.000, wall=869, train_wall=791, accuracy=0.659768
| epoch 004:    175 / 609 loss=1.205, nll_loss=0.050, ppl=1.04, wps=942, ups=2, wpb=386.790, bsz=16.000, num_updates=2002, lr=3.50175e-06, gnorm=36.961, clip=0.000, oom=0.000, loss_scale=64.000, wall=879, train_wall=800, accuracy=0.658381
| epoch 004:    200 / 609 loss=1.197, nll_loss=0.050, ppl=1.03, wps=940, ups=2, wpb=385.791, bsz=16.000, num_updates=2027, lr=3.41404e-06, gnorm=36.698, clip=0.000, oom=0.000, loss_scale=64.000, wall=890, train_wall=811, accuracy=0.664801
| epoch 004:    225 / 609 loss=1.184, nll_loss=0.049, ppl=1.03, wps=940, ups=2, wpb=385.553, bsz=16.000, num_updates=2052, lr=3.32632e-06, gnorm=36.814, clip=0.000, oom=0.000, loss_scale=64.000, wall=900, train_wall=821, accuracy=0.667865
| epoch 004:    250 / 609 loss=1.186, nll_loss=0.049, ppl=1.03, wps=941, ups=2, wpb=385.625, bsz=16.000, num_updates=2077, lr=3.2386e-06, gnorm=37.113, clip=0.000, oom=0.000, loss_scale=64.000, wall=910, train_wall=830, accuracy=0.665837
| epoch 004:    275 / 609 loss=1.176, nll_loss=0.049, ppl=1.03, wps=939, ups=2, wpb=385.170, bsz=16.000, num_updates=2102, lr=3.15088e-06, gnorm=37.218, clip=0.000, oom=0.000, loss_scale=64.000, wall=920, train_wall=841, accuracy=0.670063
| epoch 004:    300 / 609 loss=1.180, nll_loss=0.049, ppl=1.03, wps=940, ups=2, wpb=386.047, bsz=16.000, num_updates=2127, lr=3.06316e-06, gnorm=37.508, clip=0.000, oom=0.000, loss_scale=64.000, wall=931, train_wall=851, accuracy=0.670681
| epoch 004:    325 / 609 loss=1.179, nll_loss=0.049, ppl=1.03, wps=942, ups=2, wpb=386.255, bsz=16.000, num_updates=2152, lr=2.97544e-06, gnorm=37.528, clip=0.000, oom=0.000, loss_scale=64.000, wall=941, train_wall=861, accuracy=0.669862
| epoch 004:    350 / 609 loss=1.178, nll_loss=0.049, ppl=1.03, wps=941, ups=2, wpb=385.613, bsz=16.000, num_updates=2177, lr=2.88772e-06, gnorm=37.630, clip=0.000, oom=0.000, loss_scale=64.000, wall=951, train_wall=871, accuracy=0.669516
| epoch 004:    375 / 609 loss=1.175, nll_loss=0.049, ppl=1.03, wps=941, ups=2, wpb=385.721, bsz=16.000, num_updates=2202, lr=2.8e-06, gnorm=37.577, clip=0.000, oom=0.000, loss_scale=64.000, wall=961, train_wall=881, accuracy=0.669382
| epoch 004:    400 / 609 loss=1.177, nll_loss=0.049, ppl=1.03, wps=941, ups=2, wpb=385.791, bsz=16.000, num_updates=2227, lr=2.71228e-06, gnorm=37.676, clip=0.000, oom=0.000, loss_scale=64.000, wall=971, train_wall=891, accuracy=0.667238
| epoch 004:    425 / 609 loss=1.174, nll_loss=0.049, ppl=1.03, wps=943, ups=2, wpb=386.484, bsz=16.000, num_updates=2252, lr=2.62456e-06, gnorm=37.584, clip=0.000, oom=0.000, loss_scale=64.000, wall=982, train_wall=901, accuracy=0.668427
| epoch 004:    450 / 609 loss=1.173, nll_loss=0.049, ppl=1.03, wps=941, ups=2, wpb=385.869, bsz=15.993, num_updates=2277, lr=2.53684e-06, gnorm=37.588, clip=0.000, oom=0.000, loss_scale=64.000, wall=992, train_wall=911, accuracy=0.670595
| epoch 004:    475 / 609 loss=1.176, nll_loss=0.049, ppl=1.03, wps=943, ups=2, wpb=386.158, bsz=15.994, num_updates=2302, lr=2.44912e-06, gnorm=37.579, clip=0.000, oom=0.000, loss_scale=64.000, wall=1002, train_wall=921, accuracy=0.670169
| epoch 004:    500 / 609 loss=1.172, nll_loss=0.049, ppl=1.03, wps=944, ups=2, wpb=386.277, bsz=15.994, num_updates=2327, lr=2.3614e-06, gnorm=37.526, clip=0.000, oom=0.000, loss_scale=64.000, wall=1012, train_wall=931, accuracy=0.672407
| epoch 004:    525 / 609 loss=1.169, nll_loss=0.048, ppl=1.03, wps=943, ups=2, wpb=386.323, bsz=15.994, num_updates=2352, lr=2.27368e-06, gnorm=37.551, clip=0.000, oom=0.000, loss_scale=64.000, wall=1023, train_wall=941, accuracy=0.674076
| epoch 004:    550 / 609 loss=1.169, nll_loss=0.048, ppl=1.03, wps=943, ups=2, wpb=386.240, bsz=15.995, num_updates=2377, lr=2.18596e-06, gnorm=37.481, clip=0.000, oom=0.000, loss_scale=64.000, wall=1033, train_wall=951, accuracy=0.674345
| epoch 004:    575 / 609 loss=1.165, nll_loss=0.048, ppl=1.03, wps=944, ups=2, wpb=386.340, bsz=15.995, num_updates=2402, lr=2.09825e-06, gnorm=37.376, clip=0.000, oom=0.000, loss_scale=64.000, wall=1043, train_wall=961, accuracy=0.676327
| epoch 004:    600 / 609 loss=1.164, nll_loss=0.048, ppl=1.03, wps=944, ups=2, wpb=385.988, bsz=15.995, num_updates=2427, lr=2.01053e-06, gnorm=37.435, clip=0.000, oom=0.000, loss_scale=64.000, wall=1053, train_wall=971, accuracy=0.67648
| epoch 004 | loss 1.164 | nll_loss 0.048 | ppl 1.03 | wps 943 | ups 2 | wpb 385.929 | bsz 15.995 | num_updates 2435 | lr 1.98246e-06 | gnorm 37.498 | clip 0.000 | oom 0.000 | loss_scale 64.000 | wall 1056 | train_wall 974 | accuracy 0.677035
| epoch 004 | valid on 'valid' subset | loss 1.328 | nll_loss 0.055 | ppl 1.04 | num_updates 2435 | best_accuracy 0.649838 | accuracy 0.649838
| saved checkpoint checkpoints/checkpoint_best.pt (epoch 4 @ 2435 updates) (writing took 0.35823607444763184 seconds)
| epoch 005:     25 / 609 loss=1.071, nll_loss=0.044, ppl=1.03, wps=961, ups=2, wpb=390.231, bsz=16.000, num_updates=2461, lr=1.89123e-06, gnorm=36.378, clip=0.000, oom=0.000, loss_scale=64.000, wall=1085, train_wall=984, accuracy=0.694712
| epoch 005:     50 / 609 loss=1.091, nll_loss=0.045, ppl=1.03, wps=946, ups=2, wpb=383.765, bsz=16.000, num_updates=2486, lr=1.80351e-06, gnorm=37.497, clip=0.000, oom=0.000, loss_scale=64.000, wall=1095, train_wall=994, accuracy=0.696078
| epoch 005:     75 / 609 loss=1.064, nll_loss=0.044, ppl=1.03, wps=947, ups=2, wpb=383.803, bsz=16.000, num_updates=2511, lr=1.71579e-06, gnorm=37.293, clip=0.000, oom=0.000, loss_scale=64.000, wall=1105, train_wall=1004, accuracy=0.697368
| epoch 005:    100 / 609 loss=1.048, nll_loss=0.044, ppl=1.03, wps=949, ups=2, wpb=381.871, bsz=16.000, num_updates=2536, lr=1.62807e-06, gnorm=37.328, clip=0.000, oom=0.000, loss_scale=64.000, wall=1115, train_wall=1014, accuracy=0.706683
| epoch 005:    125 / 609 loss=1.058, nll_loss=0.044, ppl=1.03, wps=951, ups=2, wpb=383.175, bsz=16.000, num_updates=2561, lr=1.54035e-06, gnorm=37.942, clip=0.000, oom=0.000, loss_scale=64.000, wall=1125, train_wall=1023, accuracy=0.704861
| epoch 005:    150 / 609 loss=1.055, nll_loss=0.044, ppl=1.03, wps=947, ups=2, wpb=382.417, bsz=16.000, num_updates=2586, lr=1.45263e-06, gnorm=37.791, clip=0.000, oom=0.000, loss_scale=64.000, wall=1135, train_wall=1033, accuracy=0.705712
| epoch 005:    175 / 609 loss=1.037, nll_loss=0.043, ppl=1.03, wps=948, ups=2, wpb=383.131, bsz=16.000, num_updates=2611, lr=1.36491e-06, gnorm=37.734, clip=0.000, oom=0.000, loss_scale=64.000, wall=1145, train_wall=1043, accuracy=0.711648
| epoch 005:    200 / 609 loss=1.032, nll_loss=0.043, ppl=1.03, wps=946, ups=2, wpb=382.672, bsz=16.000, num_updates=2636, lr=1.27719e-06, gnorm=37.833, clip=0.000, oom=0.000, loss_scale=64.000, wall=1156, train_wall=1053, accuracy=0.713308
| epoch 005:    225 / 609 loss=1.041, nll_loss=0.044, ppl=1.03, wps=946, ups=2, wpb=382.562, bsz=16.000, num_updates=2661, lr=1.18947e-06, gnorm=38.219, clip=0.000, oom=0.000, loss_scale=64.000, wall=1166, train_wall=1063, accuracy=0.714325
| epoch 005:    250 / 609 loss=1.044, nll_loss=0.044, ppl=1.03, wps=948, ups=2, wpb=383.410, bsz=16.000, num_updates=2686, lr=1.10175e-06, gnorm=38.282, clip=0.000, oom=0.000, loss_scale=64.000, wall=1176, train_wall=1073, accuracy=0.713396
| epoch 005:    275 / 609 loss=1.044, nll_loss=0.044, ppl=1.03, wps=948, ups=2, wpb=383.279, bsz=16.000, num_updates=2711, lr=1.01404e-06, gnorm=38.239, clip=0.000, oom=0.000, loss_scale=64.000, wall=1186, train_wall=1083, accuracy=0.715806
| epoch 005:    300 / 609 loss=1.050, nll_loss=0.044, ppl=1.03, wps=948, ups=2, wpb=384.143, bsz=16.000, num_updates=2736, lr=9.26316e-07, gnorm=38.303, clip=0.000, oom=0.000, loss_scale=64.000, wall=1196, train_wall=1093, accuracy=0.715116
| epoch 005:    325 / 609 loss=1.055, nll_loss=0.044, ppl=1.03, wps=948, ups=2, wpb=384.561, bsz=15.991, num_updates=2761, lr=8.38596e-07, gnorm=38.259, clip=0.000, oom=0.000, loss_scale=64.000, wall=1207, train_wall=1103, accuracy=0.713792
| epoch 005:    350 / 609 loss=1.052, nll_loss=0.044, ppl=1.03, wps=949, ups=2, wpb=385.111, bsz=15.991, num_updates=2786, lr=7.50877e-07, gnorm=38.366, clip=0.000, oom=0.000, loss_scale=64.000, wall=1217, train_wall=1113, accuracy=0.714947
| epoch 005:    375 / 609 loss=1.053, nll_loss=0.044, ppl=1.03, wps=949, ups=2, wpb=385.439, bsz=15.992, num_updates=2811, lr=6.63158e-07, gnorm=38.485, clip=0.000, oom=0.000, loss_scale=64.000, wall=1227, train_wall=1123, accuracy=0.714785
| epoch 005:    400 / 609 loss=1.049, nll_loss=0.044, ppl=1.03, wps=949, ups=2, wpb=385.521, bsz=15.993, num_updates=2836, lr=5.75439e-07, gnorm=38.424, clip=0.000, oom=0.000, loss_scale=64.000, wall=1237, train_wall=1133, accuracy=0.716981
| epoch 005:    425 / 609 loss=1.043, nll_loss=0.043, ppl=1.03, wps=950, ups=2, wpb=385.721, bsz=15.993, num_updates=2861, lr=4.87719e-07, gnorm=38.373, clip=0.000, oom=0.000, loss_scale=64.000, wall=1247, train_wall=1143, accuracy=0.718626
| epoch 005:    450 / 609 loss=1.043, nll_loss=0.043, ppl=1.03, wps=951, ups=2, wpb=386.040, bsz=15.993, num_updates=2886, lr=4e-07, gnorm=38.375, clip=0.000, oom=0.000, loss_scale=64.000, wall=1257, train_wall=1153, accuracy=0.719118
| epoch 005:    475 / 609 loss=1.044, nll_loss=0.043, ppl=1.03, wps=950, ups=2, wpb=386.071, bsz=15.994, num_updates=2911, lr=3.12281e-07, gnorm=38.476, clip=0.000, oom=0.000, loss_scale=64.000, wall=1268, train_wall=1163, accuracy=0.718771
| epoch 005:    500 / 609 loss=1.040, nll_loss=0.043, ppl=1.03, wps=950, ups=2, wpb=385.820, bsz=15.994, num_updates=2936, lr=2.24561e-07, gnorm=38.407, clip=0.000, oom=0.000, loss_scale=64.000, wall=1278, train_wall=1173, accuracy=0.719456
| epoch 005:    525 / 609 loss=1.038, nll_loss=0.043, ppl=1.03, wps=950, ups=2, wpb=386.046, bsz=15.994, num_updates=2961, lr=1.36842e-07, gnorm=38.464, clip=0.000, oom=0.000, loss_scale=64.000, wall=1288, train_wall=1183, accuracy=0.719244
| epoch 005:    550 / 609 loss=1.034, nll_loss=0.043, ppl=1.03, wps=950, ups=2, wpb=386.192, bsz=15.995, num_updates=2986, lr=4.91228e-08, gnorm=38.398, clip=0.000, oom=0.000, loss_scale=64.000, wall=1298, train_wall=1193, accuracy=0.719505
| epoch 005 | loss 1.036 | nll_loss 0.043 | ppl 1.03 | wps 950 | ups 2 | wpb 386.457 | bsz 15.995 | num_updates 3000 | lr 0 | gnorm 38.489 | clip 0.000 | oom 0.000 | loss_scale 64.000 | wall 1304 | train_wall 1199 | accuracy 0.717827
| epoch 005 | valid on 'valid' subset | loss 1.360 | nll_loss 0.057 | ppl 1.04 | num_updates 3000 | best_accuracy 0.649838 | accuracy 0.638474
| done training in 1315.6 seconds
